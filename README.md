# ğŸ§˜ Wellness Tourism â€“ End-to-End MLOps Pipeline (GitHub Actions + Hugging Face)

This project builds a complete *MLOps workflow* for a Wellness Tourism Classification Model using:

- GitHub Actions (CI/CD)
- Hugging Face Datasets Hub (Data Source)
- scikit-learn Machine Learning Models
- Automatic Model Evaluation + Upload to Hugging Face
- Auto-commit of pipeline outputs back to GitHub

It demonstrates your ability to work with *real-world MLOps, automation, CI/CD, GitHub Actions, and Hugging Face integration*.

---

## ğŸš€ *Project Goals*

1. Load dataset from Hugging Face Hub  
2. Preprocess and clean the dataset  
3. Train ML model (Random Forest / XGBoost)  
4. Evaluate model performance  
5. Upload final model to Hugging Face Model Hub  
6. Automatically push artifacts into GitHub via GitHub Actions  

---

## ğŸ“‚ *Project Structure*
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ push_to_hub.py
â”‚
â”œâ”€â”€ models/                     # Auto-generated by pipeline
â”œâ”€â”€ data/                       # Auto-generated by pipeline
â”œâ”€â”€ artifacts/                  # Metrics, plots, feature importance
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .github/
â””â”€â”€ workflows/
â””â”€â”€ pipeline.yml   # CI/CD workflow

## ğŸ¤– *ML Algorithms Used*

- Random Forest Classifier  
- Feature Encoding (Label Encoding / One-Hot Encoding)  
- Train-test Split  
- Imputation for missing values  

You can easily plug in XGBoost or any other ML model later.

---

## ğŸ”„ *CI/CD Pipeline (GitHub Actions)*

### The workflow does the following automatically:

| Step | Description |
|------|-------------|
| 1. Checkout Repo | Gets latest code |
| 2. Install Dependencies | From requirements.txt |
| 3. Load Dataset | Pulls dataset from Hugging Face |
| 4. Preprocess Dataset | Cleans + encodes features |
| 5. Train Model | Saves model + encoders |
| 6. Evaluate Model | Generates metrics |
| 7. Upload Model | Pushes to Hugging Face Model Hub |
| 8. Auto Commit | Commits artifacts back to GitHub |

---

## âš™ï¸ *GitHub Actions Setup*

Create secret:
HF_TOKEN = your Hugging Face write token

Required permissions (Settings â†’ Actions â†’ General):

- *Allow all actions*
- *Workflow permissions â†’ Read & Write*

---

## ğŸ§  *Dataset*

The dataset is hosted on Hugging Face:
Required permissions (Settings â†’ Actions â†’ General):
- *Allow all actions*
- *Workflow permissions â†’ Read & Write*

  ---

## ğŸ§  *Dataset*

The dataset is hosted on Hugging Face:
chandra1024/tourism_wellness

It contains:

- Tourist activity preferences  
- Wellness category labels  
- Demographics  
- Travel patterns and habits  

---

## ğŸ“ˆ *Model Outputs*
The pipeline generates:

- model.pkl â€“ trained classifier  
- encoder.pkl â€“ preprocessing encoders  
- metrics.json â€“ accuracy, f1-score, recall, precision  
- Feature importance plots  
- Cleaned dataset  

All saved in:
artifacts/
models/
data/

## â˜ï¸ *Model Deployment to Hugging Face*

Your trained model will automatically appear here:
https://huggingface.co/spaces/chandra1024/tourism_wellness

ğŸ§‘â€ğŸ’» Technologies Used
	â€¢	Python
	â€¢	Pandas, NumPy
	â€¢	Scikit-learn
	â€¢	HuggingFace Hub
	â€¢	GitHub Actions
	â€¢	YAML (CI/CD)
	â€¢	JSON (model evaluation)
	â€¢	Matplotlib (plots)

â¸»

â­ Project Highlights
	â€¢	Fully automated MLOps pipeline
	â€¢	Real dataset from Hugging Face
	â€¢	Professional GitHub Actions workflow
	â€¢	Clean folder structure
	â€¢	Auto model deployment to HF
	â€¢	End-to-end reproducibility

â¸»

ğŸ† Author

Chandrakala Somanath Chippa
GitHub: chandra1024
Email: chandra.chippa@gmail.com

â¸»

ğŸ“ License

This project is licensed under the MIT License.
